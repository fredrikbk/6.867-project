after years of effort voice recognition is starting to work so maybe you wont be talking to your car anytime soon the way microsoft and ford would like you to be odds are though that you are already on speaking terms with silicon probably more than you realize and you can expect to be chatting it up more and more almost since computers were invented computer scientists have been working to get the machines to understand what people are saying to them until the past few years they hadnt been successful enough to offer anything but lab demos now though computer speech recognition is sufficiently advanced that it is showing up in a surprising variety of places like automobiles this past sunday at the big consumer electronics show in las vegas bill gates and ford motor executives described how microsofts sync software will let drivers use spoken commands to play music and dial their phones actually driving the car using voice commands isnt in the cards at least not for a while vista the new version of windows has some fairly advanced voice recognition software built into it but microsoft isnt making much of that in its marketing of the software and users who want to explore voice in vista will probably have to do so without a lot of help from microsoft the leading personal computer product for speech recognition is called naturally speaking the product has a somewhat serpentine history it is now owned by nuance communications formerly scansoft which through a series of acquisitions like that of dictaphone is trying to remake itself as the countrys leading supplier of speech recognition technology most people using naturally speaking say it works acceptably well right out of the box though you have to be more careful with enunciation that you would otherwise be you speak into a microphone and the words appear on the screen corrections are easy to make as the program gets trained to your speaking style and vice versa accuracy rates improve while voice controlled computers are sci fi staples in practice most people find a keyboard and a mouse are fine for telling a pc what to do bill meisel a veteran observer of the speech recognition market says the main use of speech recognition at the moment is in specialized applications like law and medicine radiologists for example are increasingly dictating their diagnoses and observations into a speech recognition program rather than into a tape recorder that must later be transcribed at its core speech recognition takes advantage of extraordinarily complex statistical methods to match the sounds you say with the right words the steady increase in computer power means that software can now be "trained" for many thousands of hours before it gets shipped as opposed to mere dozens of hours years ago one of the biggest applications of the technology is in call centers many directory assistance services use some form of speech recognition often from nuance to be able to process a request without the need for a human operator and more complicated sales and support tasks are being automated as well you can now buy or try to buy a plane ticket by talking to an airlines computers for all of my fascination with the technology of speech recognition i too would rather have a person on the other end too bad these jobs are being outsourced from human beings altogether up next predicts mr meisel will be the use of speech recognition to search the web google and yahoo are both expected to introduce voice based search for mobile phone users soon in which you say what you are searching for and hear the selections spoken back to you both companies have hired speech recognition experts indeed yahoo got into a legal tiff with nuance when it hired away nuance engineers ibm which has long had a well regarded speech recognition research effort has ambitious plans like a program that can monitor a meeting with four or five people taking part and then produce an accurate transcript since most programs now deal only with a single speaker that is still a bit in the future but david nahamoo who oversees ibms speech research says that some other new applications are already at hand one is a system that produces automatic translations of foreign language broadcasts such as those in arabic first by performing speech recognition of the spoken words and then by using translation software to render things in english the system is very far from being perfect but its good enough to give the gist of what is being said for a u s government agency short of arabic speakers but still trying to monitor events that may be good enough outside of intelligence services there is quite a market for some of the pieces of such a system for example tv stations are being pressured to provide closed captioning for hearing impaired viewers but dont have the staff to do so software might be good enough in a few years to handle that automatically the same might work on a professors lecture imagine sleeping through class but not missing a single word email me at lee gomes wsj com 
